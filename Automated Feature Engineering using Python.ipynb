{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\rdas3\\Downloads\\Train_UWu5bXk.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\rdas3\\Downloads\\Test_u94Q5KV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving identifiers\n",
    "test_Item_Identifier = test['Item_Identifier']\n",
    "test_Outlet_Identifier = test['Outlet_Identifier']\n",
    "sales = train['Item_Outlet_Sales']\n",
    "train.drop(['Item_Outlet_Sales'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now combine the train and test set as it saves us the trouble of performing the same step(s) twice.\n",
    "\n",
    "combi = train.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  2439\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  4016\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the missing values in the dataset.\n",
    "\n",
    "combi.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a lot of missing values in the Item_Weight and Outlet_size variables. Let’s deal with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing data\n",
    "combi['Item_Weight'].fillna(combi['Item_Weight'].mean(), inplace = True)\n",
    "combi['Outlet_Size'].fillna(\"missing\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    8485\n",
       "Regular    4824\n",
       "LF          522\n",
       "reg         195\n",
       "low fat     178\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It seems Item_Fat_Content contains only two categories, i.e., “Low Fat” and “Regular” – the rest of them we will consider redundant. So, let’s convert it into a binary variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to replace the categories\n",
    "fat_content_dict = {'Low Fat':0, 'Regular':1, 'LF':0, 'reg':1, 'low fat':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "map() got an unexpected keyword argument 'regex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ef9f94b3e82d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Item_Fat_Content'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Item_Fat_Content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfat_content_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: map() got an unexpected keyword argument 'regex'"
     ]
    }
   ],
   "source": [
    "combi['Item_Fat_Content'] = combi['Item_Fat_Content'].map(fat_content_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi['Item_Fat_Content'] = combi['Item_Fat_Content'].map(fat_content_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is necessary to have a unique identifier feature in the dataset (our dataset doesn’t have any right now). So, we will create one unique ID for our combined dataset. If you notice, we have two IDs in our data—one for the item and another for the outlet. So, simply concatenating both will give us a unique ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi['id'] = combi['Item_Identifier'] + combi['Outlet_Identifier']\n",
    "combi.drop(['Item_Identifier'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please note that I have dropped the feature Item_Identifier as it is no longer required. However, I have retained the feature Outlet_Identifier because I plan to use it later.\n",
    "\n",
    "#Now before proceeding, we will have to create an EntitySet. An EntitySet is a structure that contains multiple dataframes and relationships between them. So, let’s create an EntitySet and add the dataframe combination to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: sales\n",
       "  Entities:\n",
       "    bigmart [Rows: 14204, Columns: 11]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating and entity set 'es'\n",
    "es = ft.EntitySet(id = 'sales')\n",
    "\n",
    "# adding a dataframe \n",
    "es.entity_from_dataframe(entity_id = 'bigmart', dataframe = combi, index = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our data contains information at two levels—item level and outlet level. Featuretools offers a functionality to split a dataset into multiple tables. We have created a new table ‘outlet’ from the BigMart table based on the outlet ID Outlet_Identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: sales\n",
       "  Entities:\n",
       "    bigmart [Rows: 14204, Columns: 7]\n",
       "    outlet [Rows: 10, Columns: 5]\n",
       "  Relationships:\n",
       "    bigmart.Outlet_Identifier -> outlet.Outlet_Identifier"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.normalize_entity(base_entity_id='bigmart', new_entity_id='outlet', index = 'Outlet_Identifier', \n",
    "additional_variables = ['Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of EntitySet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entityset: sales\n",
      "  Entities:\n",
      "    bigmart [Rows: 14204, Columns: 7]\n",
      "    outlet [Rows: 10, Columns: 5]\n",
      "  Relationships:\n",
      "    bigmart.Outlet_Identifier -> outlet.Outlet_Identifier\n"
     ]
    }
   ],
   "source": [
    "print(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see above, it contains two entities – bigmart and outlet. There is also a relationship formed between the two tables, connected by Outlet_Identifier. This relationship will play a key role in the generation of new features.\n",
    "\n",
    "#Now we will use Deep Feature Synthesis to create new features automatically. Recall that DFS uses Feature Primitives to create features using multiple tables present in the EntitySet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 37 features\n",
      "EntitySet scattered to workers in 4.672 seconds\n",
      "Elapsed: 00:01 | Remaining: 00:00 | Progress: 100%|██████████████████████████████████████████| Calculated: 11/11 chunks\n"
     ]
    }
   ],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, \n",
    "target_entity = 'bigmart', \n",
    "max_depth = 2, \n",
    "verbose = 1, \n",
    "n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_entity is nothing but the entity ID for which we wish to create new features (in this case, it is the entity ‘bigmart’). The parameter max_depth controls the complexity of the features being generated by stacking the primitives. The parameter n_jobs helps in parallel feature computation by using multiple cores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newly created features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type',\n",
       "       'Item_MRP', 'Outlet_Identifier', 'outlet.Outlet_Establishment_Year',\n",
       "       'outlet.Outlet_Size', 'outlet.Outlet_Location_Type',\n",
       "       'outlet.Outlet_Type', 'outlet.SUM(bigmart.Item_Weight)',\n",
       "       'outlet.SUM(bigmart.Item_Fat_Content)',\n",
       "       'outlet.SUM(bigmart.Item_Visibility)', 'outlet.SUM(bigmart.Item_MRP)',\n",
       "       'outlet.STD(bigmart.Item_Weight)',\n",
       "       'outlet.STD(bigmart.Item_Fat_Content)',\n",
       "       'outlet.STD(bigmart.Item_Visibility)', 'outlet.STD(bigmart.Item_MRP)',\n",
       "       'outlet.MAX(bigmart.Item_Weight)',\n",
       "       'outlet.MAX(bigmart.Item_Fat_Content)',\n",
       "       'outlet.MAX(bigmart.Item_Visibility)', 'outlet.MAX(bigmart.Item_MRP)',\n",
       "       'outlet.SKEW(bigmart.Item_Weight)',\n",
       "       'outlet.SKEW(bigmart.Item_Fat_Content)',\n",
       "       'outlet.SKEW(bigmart.Item_Visibility)', 'outlet.SKEW(bigmart.Item_MRP)',\n",
       "       'outlet.MIN(bigmart.Item_Weight)',\n",
       "       'outlet.MIN(bigmart.Item_Fat_Content)',\n",
       "       'outlet.MIN(bigmart.Item_Visibility)', 'outlet.MIN(bigmart.Item_MRP)',\n",
       "       'outlet.MEAN(bigmart.Item_Weight)',\n",
       "       'outlet.MEAN(bigmart.Item_Fat_Content)',\n",
       "       'outlet.MEAN(bigmart.Item_Visibility)', 'outlet.MEAN(bigmart.Item_MRP)',\n",
       "       'outlet.COUNT(bigmart)', 'outlet.NUM_UNIQUE(bigmart.Item_Type)',\n",
       "       'outlet.MODE(bigmart.Item_Type)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DFS has created 29 new features in such a quick time. It is phenomenal as it would have taken much longer to do it manually. If you have datasets with multiple interrelated tables, Featuretools would still work. In that case, you wouldn’t have to normalize a table as multiple tables will already be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>outlet.Outlet_Establishment_Year</th>\n",
       "      <th>outlet.Outlet_Size</th>\n",
       "      <th>outlet.Outlet_Location_Type</th>\n",
       "      <th>outlet.Outlet_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>outlet.MIN(bigmart.Item_Fat_Content)</th>\n",
       "      <th>outlet.MIN(bigmart.Item_Visibility)</th>\n",
       "      <th>outlet.MIN(bigmart.Item_MRP)</th>\n",
       "      <th>outlet.MEAN(bigmart.Item_Weight)</th>\n",
       "      <th>outlet.MEAN(bigmart.Item_Fat_Content)</th>\n",
       "      <th>outlet.MEAN(bigmart.Item_Visibility)</th>\n",
       "      <th>outlet.MEAN(bigmart.Item_MRP)</th>\n",
       "      <th>outlet.COUNT(bigmart)</th>\n",
       "      <th>outlet.NUM_UNIQUE(bigmart.Item_Type)</th>\n",
       "      <th>outlet.MODE(bigmart.Item_Type)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DRA12OUT010</th>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068535</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>143.0154</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>missing</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.6558</td>\n",
       "      <td>12.722870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101939</td>\n",
       "      <td>141.159742</td>\n",
       "      <td>925</td>\n",
       "      <td>16</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRA12OUT013</th>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040912</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>142.3154</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.4900</td>\n",
       "      <td>12.788139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060242</td>\n",
       "      <td>141.128428</td>\n",
       "      <td>1553</td>\n",
       "      <td>16</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRA12OUT017</th>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>140.3154</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>missing</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0900</td>\n",
       "      <td>12.782080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061142</td>\n",
       "      <td>140.998931</td>\n",
       "      <td>1543</td>\n",
       "      <td>16</td>\n",
       "      <td>Snack Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRA12OUT018</th>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041113</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>142.0154</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.8900</td>\n",
       "      <td>12.803638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059976</td>\n",
       "      <td>141.000899</td>\n",
       "      <td>1546</td>\n",
       "      <td>16</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRA12OUT027</th>\n",
       "      <td>12.792854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>140.0154</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>1985</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.2900</td>\n",
       "      <td>12.792854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060344</td>\n",
       "      <td>141.012347</td>\n",
       "      <td>1559</td>\n",
       "      <td>16</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Item_Weight  Item_Fat_Content  Item_Visibility    Item_Type  \\\n",
       "id                                                                         \n",
       "DRA12OUT010    11.600000               NaN         0.068535  Soft Drinks   \n",
       "DRA12OUT013    11.600000               NaN         0.040912  Soft Drinks   \n",
       "DRA12OUT017    11.600000               NaN         0.041178  Soft Drinks   \n",
       "DRA12OUT018    11.600000               NaN         0.041113  Soft Drinks   \n",
       "DRA12OUT027    12.792854               NaN         0.040748  Soft Drinks   \n",
       "\n",
       "             Item_MRP Outlet_Identifier  outlet.Outlet_Establishment_Year  \\\n",
       "id                                                                          \n",
       "DRA12OUT010  143.0154            OUT010                              1998   \n",
       "DRA12OUT013  142.3154            OUT013                              1987   \n",
       "DRA12OUT017  140.3154            OUT017                              2007   \n",
       "DRA12OUT018  142.0154            OUT018                              2009   \n",
       "DRA12OUT027  140.0154            OUT027                              1985   \n",
       "\n",
       "            outlet.Outlet_Size outlet.Outlet_Location_Type outlet.Outlet_Type  \\\n",
       "id                                                                              \n",
       "DRA12OUT010            missing                      Tier 3      Grocery Store   \n",
       "DRA12OUT013               High                      Tier 3  Supermarket Type1   \n",
       "DRA12OUT017            missing                      Tier 2  Supermarket Type1   \n",
       "DRA12OUT018             Medium                      Tier 3  Supermarket Type2   \n",
       "DRA12OUT027             Medium                      Tier 3  Supermarket Type3   \n",
       "\n",
       "                          ...                \\\n",
       "id                        ...                 \n",
       "DRA12OUT010               ...                 \n",
       "DRA12OUT013               ...                 \n",
       "DRA12OUT017               ...                 \n",
       "DRA12OUT018               ...                 \n",
       "DRA12OUT027               ...                 \n",
       "\n",
       "             outlet.MIN(bigmart.Item_Fat_Content)  \\\n",
       "id                                                  \n",
       "DRA12OUT010                                   NaN   \n",
       "DRA12OUT013                                   NaN   \n",
       "DRA12OUT017                                   NaN   \n",
       "DRA12OUT018                                   NaN   \n",
       "DRA12OUT027                                   NaN   \n",
       "\n",
       "             outlet.MIN(bigmart.Item_Visibility)  \\\n",
       "id                                                 \n",
       "DRA12OUT010                                  0.0   \n",
       "DRA12OUT013                                  0.0   \n",
       "DRA12OUT017                                  0.0   \n",
       "DRA12OUT018                                  0.0   \n",
       "DRA12OUT027                                  0.0   \n",
       "\n",
       "             outlet.MIN(bigmart.Item_MRP)  outlet.MEAN(bigmart.Item_Weight)  \\\n",
       "id                                                                            \n",
       "DRA12OUT010                       32.6558                         12.722870   \n",
       "DRA12OUT013                       31.4900                         12.788139   \n",
       "DRA12OUT017                       32.0900                         12.782080   \n",
       "DRA12OUT018                       31.8900                         12.803638   \n",
       "DRA12OUT027                       31.2900                         12.792854   \n",
       "\n",
       "             outlet.MEAN(bigmart.Item_Fat_Content)  \\\n",
       "id                                                   \n",
       "DRA12OUT010                                    NaN   \n",
       "DRA12OUT013                                    NaN   \n",
       "DRA12OUT017                                    NaN   \n",
       "DRA12OUT018                                    NaN   \n",
       "DRA12OUT027                                    NaN   \n",
       "\n",
       "             outlet.MEAN(bigmart.Item_Visibility)  \\\n",
       "id                                                  \n",
       "DRA12OUT010                              0.101939   \n",
       "DRA12OUT013                              0.060242   \n",
       "DRA12OUT017                              0.061142   \n",
       "DRA12OUT018                              0.059976   \n",
       "DRA12OUT027                              0.060344   \n",
       "\n",
       "             outlet.MEAN(bigmart.Item_MRP)  outlet.COUNT(bigmart)  \\\n",
       "id                                                                  \n",
       "DRA12OUT010                     141.159742                    925   \n",
       "DRA12OUT013                     141.128428                   1553   \n",
       "DRA12OUT017                     140.998931                   1543   \n",
       "DRA12OUT018                     141.000899                   1546   \n",
       "DRA12OUT027                     141.012347                   1559   \n",
       "\n",
       "             outlet.NUM_UNIQUE(bigmart.Item_Type)  \\\n",
       "id                                                  \n",
       "DRA12OUT010                                    16   \n",
       "DRA12OUT013                                    16   \n",
       "DRA12OUT017                                    16   \n",
       "DRA12OUT018                                    16   \n",
       "DRA12OUT027                                    16   \n",
       "\n",
       "             outlet.MODE(bigmart.Item_Type)  \n",
       "id                                           \n",
       "DRA12OUT010           Fruits and Vegetables  \n",
       "DRA12OUT013           Fruits and Vegetables  \n",
       "DRA12OUT017                     Snack Foods  \n",
       "DRA12OUT018           Fruits and Vegetables  \n",
       "DRA12OUT027           Fruits and Vegetables  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let’s print the first few rows of feature_matrix.\n",
    "\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert id, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-7fd4d6200493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcombi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[1;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[0;32m   4134\u001b[0m                 \u001b[1;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4135\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4136\u001b[1;33m                 \u001b[0mnew_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4138\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   3217\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3218\u001b[0m         self._data.insert(loc, column, value,\n\u001b[1;32m-> 3219\u001b[1;33m                           allow_duplicates=allow_duplicates)\n\u001b[0m\u001b[0;32m   3220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4336\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4337\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4338\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cannot insert {}, already exists'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4340\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert id, already exists"
     ]
    }
   ],
   "source": [
    "feature_matrix = feature_matrix.reindex(index=combi['id'])\n",
    "feature_matrix = feature_matrix.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use them to build a model and predict Item_Outlet_Sales. Since our final data (feature_matrix) has many categorical features, I decided to use the CatBoost algorithm. It can use categorical features directly and is scalable in nature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost requires all the categorical variables to be in the string format. So, we will convert the categorical variables in our data to string first:\n",
    "\n",
    "categorical_features = np.where(feature_matrix.dtypes == 'object')[0]\n",
    "\n",
    "for i in categorical_features:\n",
    "    feature_matrix.iloc[:,i] = feature_matrix.iloc[:,i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s split feature_matrix back into train and test sets.\n",
    "\n",
    "feature_matrix.drop(['id'], axis=1, inplace=True)\n",
    "train = feature_matrix[:8523]\n",
    "test = feature_matrix[8523:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing uneccesary variables\n",
    "train.drop(['Outlet_Identifier'], axis=1, inplace=True)\n",
    "test.drop(['Outlet_Identifier'], axis=1, inplace=True)\n",
    "\n",
    "# identifying categorical features\n",
    "categorical_features = np.where(train.dtypes == 'object')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the train data into training and validation set to check the model’s performance locally.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting train data into training and validation set\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train, sales, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You should provide test set for use best model. use_best_model parameter swiched to false value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2297.3467173\ttotal: 69.5ms\tremaining: 6.88s\n",
      "1:\tlearn: 2018.5649335\ttotal: 87ms\tremaining: 4.26s\n",
      "2:\tlearn: 1866.7620425\ttotal: 111ms\tremaining: 3.59s\n",
      "3:\tlearn: 1787.6466144\ttotal: 130ms\tremaining: 3.13s\n",
      "4:\tlearn: 1747.5567517\ttotal: 150ms\tremaining: 2.85s\n",
      "5:\tlearn: 1727.5650568\ttotal: 171ms\tremaining: 2.68s\n",
      "6:\tlearn: 1717.6802046\ttotal: 190ms\tremaining: 2.53s\n",
      "7:\tlearn: 1712.8138435\ttotal: 208ms\tremaining: 2.4s\n",
      "8:\tlearn: 1710.4233107\ttotal: 229ms\tremaining: 2.32s\n",
      "9:\tlearn: 1709.2502575\ttotal: 254ms\tremaining: 2.29s\n",
      "10:\tlearn: 1708.6749362\ttotal: 273ms\tremaining: 2.21s\n",
      "11:\tlearn: 1708.3928446\ttotal: 299ms\tremaining: 2.19s\n",
      "12:\tlearn: 1708.2545471\ttotal: 315ms\tremaining: 2.11s\n",
      "13:\tlearn: 1708.1867501\ttotal: 355ms\tremaining: 2.18s\n",
      "14:\tlearn: 1708.1535151\ttotal: 375ms\tremaining: 2.12s\n",
      "15:\tlearn: 1708.1372232\ttotal: 394ms\tremaining: 2.07s\n",
      "16:\tlearn: 1708.1292369\ttotal: 412ms\tremaining: 2.01s\n",
      "17:\tlearn: 1708.1253221\ttotal: 430ms\tremaining: 1.96s\n",
      "18:\tlearn: 1708.1234030\ttotal: 456ms\tremaining: 1.94s\n",
      "19:\tlearn: 1708.1224623\ttotal: 477ms\tremaining: 1.91s\n",
      "20:\tlearn: 1708.1220011\ttotal: 501ms\tremaining: 1.89s\n",
      "21:\tlearn: 1708.1217751\ttotal: 531ms\tremaining: 1.88s\n",
      "22:\tlearn: 1708.1216643\ttotal: 548ms\tremaining: 1.83s\n",
      "23:\tlearn: 1708.1216100\ttotal: 566ms\tremaining: 1.79s\n",
      "24:\tlearn: 1708.1215833\ttotal: 589ms\tremaining: 1.77s\n",
      "25:\tlearn: 1708.1215703\ttotal: 615ms\tremaining: 1.75s\n",
      "26:\tlearn: 1708.1215639\ttotal: 636ms\tremaining: 1.72s\n",
      "27:\tlearn: 1708.1215608\ttotal: 659ms\tremaining: 1.69s\n",
      "28:\tlearn: 1708.1215592\ttotal: 675ms\tremaining: 1.65s\n",
      "29:\tlearn: 1708.1215585\ttotal: 694ms\tremaining: 1.62s\n",
      "30:\tlearn: 1708.1215581\ttotal: 713ms\tremaining: 1.59s\n",
      "31:\tlearn: 1708.1215579\ttotal: 730ms\tremaining: 1.55s\n",
      "32:\tlearn: 1708.1215578\ttotal: 753ms\tremaining: 1.53s\n",
      "33:\tlearn: 1708.1215578\ttotal: 776ms\tremaining: 1.51s\n",
      "34:\tlearn: 1708.1215578\ttotal: 814ms\tremaining: 1.51s\n",
      "35:\tlearn: 1708.1215578\ttotal: 833ms\tremaining: 1.48s\n",
      "36:\tlearn: 1708.1215578\ttotal: 859ms\tremaining: 1.46s\n",
      "37:\tlearn: 1708.1215577\ttotal: 884ms\tremaining: 1.44s\n",
      "38:\tlearn: 1708.1215577\ttotal: 903ms\tremaining: 1.41s\n",
      "39:\tlearn: 1708.1215577\ttotal: 921ms\tremaining: 1.38s\n",
      "40:\tlearn: 1708.1215577\ttotal: 951ms\tremaining: 1.37s\n",
      "41:\tlearn: 1708.1215577\ttotal: 970ms\tremaining: 1.34s\n",
      "42:\tlearn: 1708.1215577\ttotal: 989ms\tremaining: 1.31s\n",
      "43:\tlearn: 1708.1215577\ttotal: 1.01s\tremaining: 1.28s\n",
      "44:\tlearn: 1708.1215577\ttotal: 1.03s\tremaining: 1.26s\n",
      "45:\tlearn: 1708.1215577\ttotal: 1.05s\tremaining: 1.23s\n",
      "46:\tlearn: 1708.1215577\ttotal: 1.07s\tremaining: 1.2s\n",
      "47:\tlearn: 1708.1215577\ttotal: 1.08s\tremaining: 1.17s\n",
      "48:\tlearn: 1708.1215577\ttotal: 1.1s\tremaining: 1.14s\n",
      "49:\tlearn: 1708.1215577\ttotal: 1.12s\tremaining: 1.12s\n",
      "50:\tlearn: 1708.1215577\ttotal: 1.13s\tremaining: 1.09s\n",
      "51:\tlearn: 1708.1215577\ttotal: 1.16s\tremaining: 1.07s\n",
      "52:\tlearn: 1708.1215577\ttotal: 1.17s\tremaining: 1.04s\n",
      "53:\tlearn: 1708.1215577\ttotal: 1.19s\tremaining: 1.01s\n",
      "54:\tlearn: 1708.1215577\ttotal: 1.22s\tremaining: 996ms\n",
      "55:\tlearn: 1708.1215577\ttotal: 1.24s\tremaining: 976ms\n",
      "56:\tlearn: 1708.1215577\ttotal: 1.26s\tremaining: 952ms\n",
      "57:\tlearn: 1708.1215577\ttotal: 1.28s\tremaining: 927ms\n",
      "58:\tlearn: 1708.1215577\ttotal: 1.31s\tremaining: 908ms\n",
      "59:\tlearn: 1708.1215577\ttotal: 1.34s\tremaining: 892ms\n",
      "60:\tlearn: 1708.1215577\ttotal: 1.36s\tremaining: 867ms\n",
      "61:\tlearn: 1708.1215577\ttotal: 1.38s\tremaining: 843ms\n",
      "62:\tlearn: 1708.1215577\ttotal: 1.4s\tremaining: 823ms\n",
      "63:\tlearn: 1708.1215577\ttotal: 1.42s\tremaining: 797ms\n",
      "64:\tlearn: 1708.1215577\ttotal: 1.44s\tremaining: 774ms\n",
      "65:\tlearn: 1708.1215577\ttotal: 1.46s\tremaining: 750ms\n",
      "66:\tlearn: 1708.1215577\ttotal: 1.47s\tremaining: 725ms\n",
      "67:\tlearn: 1708.1215577\ttotal: 1.5s\tremaining: 704ms\n",
      "68:\tlearn: 1708.1215577\ttotal: 1.51s\tremaining: 681ms\n",
      "69:\tlearn: 1708.1215577\ttotal: 1.53s\tremaining: 657ms\n",
      "70:\tlearn: 1708.1215577\ttotal: 1.55s\tremaining: 635ms\n",
      "71:\tlearn: 1708.1215577\ttotal: 1.57s\tremaining: 611ms\n",
      "72:\tlearn: 1708.1215577\ttotal: 1.59s\tremaining: 588ms\n",
      "73:\tlearn: 1708.1215577\ttotal: 1.61s\tremaining: 565ms\n",
      "74:\tlearn: 1708.1215577\ttotal: 1.63s\tremaining: 543ms\n",
      "75:\tlearn: 1708.1215577\ttotal: 1.66s\tremaining: 523ms\n",
      "76:\tlearn: 1708.1215577\ttotal: 1.69s\tremaining: 505ms\n",
      "77:\tlearn: 1708.1215577\ttotal: 1.71s\tremaining: 482ms\n",
      "78:\tlearn: 1708.1215577\ttotal: 1.73s\tremaining: 460ms\n",
      "79:\tlearn: 1708.1215577\ttotal: 1.75s\tremaining: 436ms\n",
      "80:\tlearn: 1708.1215577\ttotal: 1.76s\tremaining: 414ms\n",
      "81:\tlearn: 1708.1215577\ttotal: 1.78s\tremaining: 391ms\n",
      "82:\tlearn: 1708.1215577\ttotal: 1.8s\tremaining: 368ms\n",
      "83:\tlearn: 1708.1215577\ttotal: 1.81s\tremaining: 345ms\n",
      "84:\tlearn: 1708.1215577\ttotal: 1.83s\tremaining: 323ms\n",
      "85:\tlearn: 1708.1215577\ttotal: 1.85s\tremaining: 301ms\n",
      "86:\tlearn: 1708.1215577\ttotal: 1.87s\tremaining: 279ms\n",
      "87:\tlearn: 1708.1215577\ttotal: 1.88s\tremaining: 257ms\n",
      "88:\tlearn: 1708.1215577\ttotal: 1.9s\tremaining: 235ms\n",
      "89:\tlearn: 1708.1215577\ttotal: 1.93s\tremaining: 214ms\n",
      "90:\tlearn: 1708.1215577\ttotal: 1.95s\tremaining: 193ms\n",
      "91:\tlearn: 1708.1215577\ttotal: 1.98s\tremaining: 172ms\n",
      "92:\tlearn: 1708.1215577\ttotal: 2s\tremaining: 150ms\n",
      "93:\tlearn: 1708.1215577\ttotal: 2.02s\tremaining: 129ms\n",
      "94:\tlearn: 1708.1215577\ttotal: 2.04s\tremaining: 107ms\n",
      "95:\tlearn: 1708.1215577\ttotal: 2.06s\tremaining: 85.9ms\n",
      "96:\tlearn: 1708.1215577\ttotal: 2.08s\tremaining: 64.3ms\n",
      "97:\tlearn: 1708.1215577\ttotal: 2.1s\tremaining: 42.9ms\n",
      "98:\tlearn: 1708.1215577\ttotal: 2.12s\tremaining: 21.4ms\n",
      "99:\tlearn: 1708.1215577\ttotal: 2.15s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1701.420503735139"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, we can now train our model. The evaluation metric we will use is RMSE (Root Mean Squared Error).\n",
    "\n",
    "model_cat = CatBoostRegressor(iterations=100, learning_rate=0.3, depth=6, eval_metric='RMSE', random_seed=7)\n",
    "\n",
    "# training model\n",
    "model_cat.fit(xtrain, ytrain, cat_features=categorical_features, use_best_model=True)\n",
    "# validation score\n",
    "model_cat.score(xvalid, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
